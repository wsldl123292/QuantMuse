#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆ LLM & NLP åŠŸèƒ½æ¼”ç¤º
å±•ç¤ºæ ¸å¿ƒåŠŸèƒ½ï¼Œæ— éœ€APIå¯†é’¥
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_service.ai import NLPProcessor, SentimentFactorCalculator
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

def demo_nlp_processing():
    """æ¼”ç¤ºNLPå¤„ç†åŠŸèƒ½"""
    print("ğŸ” æ¼”ç¤ºNLPå¤„ç†åŠŸèƒ½")
    print("=" * 50)
    
    # åˆå§‹åŒ–NLPå¤„ç†å™¨
    nlp_processor = NLPProcessor(use_spacy=False, use_transformers=False)
    
    # ç¤ºä¾‹æ–‡æœ¬
    sample_texts = [
        "Apple reports strong Q4 earnings, stock surges 5% on better-than-expected iPhone sales",
        "Tesla faces production challenges, shares decline due to supply chain issues",
        "Google announces revolutionary AI breakthrough that could transform the industry",
        "Market volatility increases as investors react to Fed policy changes"
    ]
    
    print("ğŸ“ å¤„ç†ç¤ºä¾‹æ–‡æœ¬:")
    for i, text in enumerate(sample_texts, 1):
        print(f"\n{i}. åŸæ–‡: {text}")
        
        # é¢„å¤„ç†æ–‡æœ¬
        processed = nlp_processor.preprocess_text(text)
        
        print(f"   æ¸…ç†å: {processed.cleaned_text[:100]}...")
        print(f"   å…³é”®è¯: {', '.join(processed.keywords[:5])}")
        print(f"   æƒ…æ„Ÿ: {processed.sentiment_label} (å¾—åˆ†: {processed.sentiment_score:.2f})")
        print(f"   ä¸»é¢˜: {', '.join(processed.topics[:3])}")

def demo_sentiment_factor():
    """æ¼”ç¤ºæƒ…æ„Ÿå› å­ç”Ÿæˆ"""
    print("\nğŸ“Š æ¼”ç¤ºæƒ…æ„Ÿå› å­ç”Ÿæˆ")
    print("=" * 50)
    
    # åˆå§‹åŒ–æƒ…æ„Ÿå› å­è®¡ç®—å™¨
    sentiment_calculator = SentimentFactorCalculator()
    
    # æ¨¡æ‹Ÿæƒ…æ„Ÿæ•°æ®
    sentiment_data = pd.DataFrame({
        'symbol': ['AAPL', 'GOOGL', 'TSLA', 'MSFT', 'AMZN'] * 10,
        'date': pd.date_range('2024-01-01', periods=50, freq='D').repeat(5),
        'sentiment_score': np.random.normal(0, 0.3, 50),
        'volume': np.random.randint(100, 1000, 50),
        'source': ['news', 'twitter', 'reddit'] * 16 + ['news', 'twitter']
    })
    
    print("ğŸ“ˆ ç”Ÿæˆæƒ…æ„Ÿå› å­:")
    
    # è®¡ç®—å„ç§æƒ…æ„Ÿå› å­
    factors = sentiment_calculator.calculate_sentiment_factors(sentiment_data)
    
    for factor_name, factor_data in factors.items():
        if isinstance(factor_data, dict):
            print(f"\n{factor_name}:")
            for symbol, value in list(factor_data.items())[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"  {symbol}: {value:.4f}")
        else:
            print(f"{factor_name}: {factor_data:.4f}")

def demo_market_analysis():
    """æ¼”ç¤ºå¸‚åœºåˆ†æåŠŸèƒ½"""
    print("\nğŸ¯ æ¼”ç¤ºå¸‚åœºåˆ†æåŠŸèƒ½")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿå¸‚åœºæ•°æ®
    dates = pd.date_range('2024-01-01', periods=30, freq='D')
    symbols = ['AAPL', 'GOOGL', 'TSLA']
    
    market_data = {}
    for symbol in symbols:
        base_price = np.random.uniform(100, 500)
        returns = np.random.normal(0.001, 0.02, len(dates))
        prices = [base_price]
        
        for ret in returns[1:]:
            prices.append(prices[-1] * (1 + ret))
        
        market_data[symbol] = pd.DataFrame({
            'date': dates,
            'close': prices,
            'volume': np.random.randint(1000000, 10000000, len(dates))
        })
    
    # æ¨¡æ‹Ÿæƒ…æ„Ÿæ•°æ®
    sentiment_data = pd.DataFrame({
        'symbol': symbols * 10,
        'date': pd.date_range('2024-01-01', periods=30, freq='D').repeat(len(symbols)),
        'sentiment_score': np.random.normal(0, 0.3, 30 * len(symbols)),
        'volume': np.random.randint(100, 1000, 30 * len(symbols))
    })
    
    print("ğŸ“Š å¸‚åœºåˆ†æç»“æœ:")
    
    # è®¡ç®—å¸‚åœºæƒ…ç»ªæŒ‡æ ‡
    sentiment_calculator = SentimentFactorCalculator()
    market_sentiment = sentiment_calculator.calculate_market_sentiment(sentiment_data)
    
    print(f"æ•´ä½“å¸‚åœºæƒ…ç»ª: {market_sentiment['overall_sentiment']:.2f}")
    print(f"æƒ…ç»ªæ³¢åŠ¨æ€§: {market_sentiment['sentiment_volatility']:.4f}")
    print(f"æƒ…ç»ªä¸€è‡´æ€§: {market_sentiment['sentiment_consensus']:.2f}")
    
    # æŒ‰è‚¡ç¥¨åˆ†æ
    print("\nå„è‚¡ç¥¨æƒ…ç»ªåˆ†æ:")
    for symbol in symbols:
        symbol_sentiment = sentiment_data[sentiment_data['symbol'] == symbol]['sentiment_score'].mean()
        print(f"  {symbol}: {symbol_sentiment:.3f}")

def demo_strategy_integration():
    """æ¼”ç¤ºä¸ç­–ç•¥ç³»ç»Ÿçš„é›†æˆ"""
    print("\nâš™ï¸ æ¼”ç¤ºä¸ç­–ç•¥ç³»ç»Ÿé›†æˆ")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿå› å­æ•°æ®
    factor_data = pd.DataFrame({
        'symbol': ['AAPL', 'GOOGL', 'TSLA', 'MSFT', 'AMZN'] * 5,
        'date': pd.date_range('2024-01-01', periods=25, freq='D').repeat(5),
        'factor_name': ['sentiment_momentum', 'sentiment_volatility', 'news_volume', 'social_volume', 'sentiment_consensus'] * 5,
        'factor_value': np.random.normal(0, 1, 125)
    })
    
    # æ¨¡æ‹Ÿä»·æ ¼æ•°æ®
    price_data = pd.DataFrame({
        'symbol': ['AAPL', 'GOOGL', 'TSLA', 'MSFT', 'AMZN'] * 5,
        'date': pd.date_range('2024-01-01', periods=25, freq='D').repeat(5),
        'close': np.random.uniform(100, 500, 125)
    })
    
    print("ğŸ”— æƒ…æ„Ÿå› å­ä¸ç­–ç•¥é›†æˆ:")
    
    # è®¡ç®—æƒ…æ„Ÿå› å­æƒé‡
    sentiment_factors = factor_data[factor_data['factor_name'].str.contains('sentiment')]
    
    print("æƒ…æ„Ÿå› å­ç»Ÿè®¡:")
    for factor_name in sentiment_factors['factor_name'].unique():
        factor_values = sentiment_factors[sentiment_factors['factor_name'] == factor_name]['factor_value']
        print(f"  {factor_name}: å‡å€¼={factor_values.mean():.3f}, æ ‡å‡†å·®={factor_values.std():.3f}")
    
    # æ¨¡æ‹Ÿç­–ç•¥ä¿¡å·
    print("\nç­–ç•¥ä¿¡å·ç”Ÿæˆ:")
    signals = []
    for symbol in ['AAPL', 'GOOGL', 'TSLA']:
        symbol_sentiment = sentiment_factors[sentiment_factors['symbol'] == symbol]['factor_value'].mean()
        
        if symbol_sentiment > 0.5:
            signal = "å¼ºçƒˆä¹°å…¥"
        elif symbol_sentiment > 0:
            signal = "ä¹°å…¥"
        elif symbol_sentiment > -0.5:
            signal = "æŒæœ‰"
        else:
            signal = "å–å‡º"
        
        signals.append((symbol, symbol_sentiment, signal))
        print(f"  {symbol}: æƒ…æ„Ÿå¾—åˆ†={symbol_sentiment:.3f} â†’ {signal}")

def main():
    """ä¸»å‡½æ•°"""
    setup_logging()
    
    print("ğŸš€ LLM & NLP æ‰©å±•æ¨¡å—æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # æ¼”ç¤ºå„ä¸ªåŠŸèƒ½æ¨¡å—
        demo_nlp_processing()
        demo_sentiment_factor()
        demo_market_analysis()
        demo_strategy_integration()
        
        print("\nâœ… æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ“‹ åŠŸèƒ½æ€»ç»“:")
        print("  â€¢ NLPæ–‡æœ¬å¤„ç†: æ¸…ç†ã€åˆ†è¯ã€å…³é”®è¯æå–ã€æƒ…æ„Ÿåˆ†æ")
        print("  â€¢ æƒ…æ„Ÿå› å­ç”Ÿæˆ: åŠ¨é‡ã€æ³¢åŠ¨æ€§ã€æˆäº¤é‡ã€ä¸€è‡´æ€§")
        print("  â€¢ å¸‚åœºåˆ†æ: æ•´ä½“æƒ…ç»ªã€ä¸ªè‚¡æƒ…ç»ªã€è¶‹åŠ¿åˆ†æ")
        print("  â€¢ ç­–ç•¥é›†æˆ: æƒ…æ„Ÿå› å­æƒé‡ã€äº¤æ˜“ä¿¡å·ç”Ÿæˆ")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 